{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NROhZ-m_d3j1"
      },
      "source": [
        "### **News Article Text Classification**\n",
        "This project performs supervised machine learning with text classification. Text classification is the process of assigning categories of text according to its content. More specifically, we are performing Naive Bayes classifier on news articles based on the articles's title to predict its category. \n",
        "\n",
        "The dataset that is used for training and testing contains over 120,000 samples of news article titles from over 2000 different news sources. Each sample contains the title of an article and its class label ranging from 0 to 3 which correspond to the four main categories of world, sports, business and science/tech."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ks3YYZ6fx-4"
      },
      "source": [
        "**Setup code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6VIeLX6d0Xc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "np.random.seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw9nA16pf7T_"
      },
      "source": [
        "**Read csv files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hehP_8BGfLkH"
      },
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "j7XUg-I__UGr",
        "outputId": "9ff1d29f-86df-455e-9673-e20e8a461d75"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
              "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
              "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
              "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
              "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Oil prices soar to all-time record, posing new...</td>\n",
              "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ...                                        description\n",
              "0      3  ...  Reuters - Short-sellers, Wall Street's dwindli...\n",
              "1      3  ...  Reuters - Private investment firm Carlyle Grou...\n",
              "2      3  ...  Reuters - Soaring crude prices plus worries\\ab...\n",
              "3      3  ...  Reuters - Authorities have halted oil export\\f...\n",
              "4      3  ...  AFP - Tearaway world oil prices, toppling reco...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkDBs76HhSCm"
      },
      "source": [
        "**Create training and test sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrgatjyhfX4n"
      },
      "source": [
        "X_train = np.array(df_train['title'])\n",
        "y_train = np.array(df_train['label'])\n",
        "X_test = np.array(df_test['title'])\n",
        "y_test = np.array(df_test['label'])\n",
        "\n",
        "for i in range(y_train.shape[0]):\n",
        "  y_train[i] -= 1\n",
        "for i in range(y_test.shape[0]):\n",
        "  y_test[i] -= 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMdas-SkkqIX"
      },
      "source": [
        "**Bag of words** \n",
        "- Convert title strings to lower case\n",
        "- Remove punctuation\n",
        "- Split string into individual words\n",
        "- Count frequency of each word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nfZreH5ixl6"
      },
      "source": [
        "def count_frequency(documents):\n",
        "    \"\"\"\n",
        "    count occurrence of each word in the list.\n",
        "    Inputs:\n",
        "    - documents: list, each entity is a string type representing the title of an article\n",
        "    Outputs:\n",
        "    - frequency: a dictionary. The key is the unique words, and the value is the number of occurrences of the word\n",
        "    \"\"\"\n",
        "\n",
        "    # convert to lower case\n",
        "    lower_case_doc = []\n",
        "    for s in documents:\n",
        "      lower_case_doc.append(s.lower())\n",
        "\n",
        "    # remove punctuation\n",
        "    no_punc_doc = []\n",
        "    for s in lower_case_doc:\n",
        "      no_punc_doc.append(s.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "    # split strings into words\n",
        "    words_doc = []\n",
        "    for s in no_punc_doc:\n",
        "      for w in s.split():\n",
        "        words_doc.append(w)\n",
        "    \n",
        "    # count the frequency of words\n",
        "    frequency = Counter(words_doc)\n",
        "\n",
        "    return frequency"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZrC3dBqgA08"
      },
      "source": [
        "**Training the Naive Bayes model**\n",
        "- compute the prior probability of each label\n",
        "- compute the conditional probabbility of words for each label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfuoSeUIgPUo"
      },
      "source": [
        "def prior_prob(y_train):\n",
        "    \"\"\"\n",
        "    compute the prior probability\n",
        "    Inputs:\n",
        "    - y_train: an array that stores ground true label for training data\n",
        "    Outputs:\n",
        "    - prior: a dictionary. key is the class label, value is the prior probability.\n",
        "    \"\"\"\n",
        "    prior = {}\n",
        "    world = 0\n",
        "    sports = 0\n",
        "    business = 0\n",
        "    science = 0\n",
        "\n",
        "    n = len(y_train)\n",
        "\n",
        "    for i in y_train:\n",
        "      if i==0:\n",
        "        world += 1\n",
        "      elif i==1:\n",
        "        sports += 1\n",
        "      elif i==2:\n",
        "        business += 1\n",
        "      elif i==3:\n",
        "        science += 1\n",
        "    \n",
        "    prior[0] = world/n\n",
        "    prior[1] = sports/n\n",
        "    prior[2] = business/n\n",
        "    prior[3] = science/n  \n",
        "    \n",
        "    return prior"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycMzYQFihrEd"
      },
      "source": [
        "def conditional_prob(X_train, y_train):\n",
        "    \"\"\"\n",
        "    compute the conditional probability for a document set\n",
        "    Inputs:\n",
        "    - X_train: an array of shape (num_train,) which stores title articles. each entity is a string type.\n",
        "    - y_train: an array of shape (num_train,). the ground true label for each training data.\n",
        "    Ouputs:\n",
        "    - cond_prob: a dictionary. key is the class label, value is a dictionary in which the key is word, the value is the conditional probability of feature x_i given y.\n",
        "    \"\"\"\n",
        "    \n",
        "    cond_prob = {}\n",
        "    words_cond_prob_label_0 = {}\n",
        "    words_cond_prob_label_1 = {}\n",
        "    words_cond_prob_label_2 = {}\n",
        "    words_cond_prob_label_3 = {}\n",
        "\n",
        "    label_0_sms = []\n",
        "    label_1_sms = []\n",
        "    label_2_sms = []\n",
        "    label_3_sms = []\n",
        "    \n",
        "    for msg, label in zip(X_train, y_train):\n",
        "      if label==0:\n",
        "        label_0_sms.append(msg)\n",
        "      elif label==1:\n",
        "        label_1_sms.append(msg)\n",
        "      elif label==2:\n",
        "        label_2_sms.append(msg)\n",
        "      elif label==3:\n",
        "        label_3_sms.append(msg)\n",
        "    \n",
        "    label_0_words = count_frequency(label_0_sms)\n",
        "    label_1_words = count_frequency(label_1_sms)\n",
        "    label_2_words = count_frequency(label_2_sms)\n",
        "    label_3_words = count_frequency(label_3_sms)\n",
        "\n",
        "    sum_label_0_words = sum(label_0_words.values())\n",
        "    sum_label_1_words = sum(label_1_words.values())\n",
        "    sum_label_2_words = sum(label_2_words.values())\n",
        "    sum_label_3_words = sum(label_3_words.values())\n",
        "\n",
        "    for w in label_0_words:\n",
        "      words_cond_prob_label_0[w] = (label_0_words[w]+1)/(sum_label_0_words+20000)\n",
        "\n",
        "    for w in label_1_words:\n",
        "      words_cond_prob_label_1[w] = (label_1_words[w]+1)/(sum_label_1_words+20000)\n",
        "    \n",
        "    for w in label_2_words:\n",
        "      words_cond_prob_label_2[w] = (label_2_words[w]+1)/(sum_label_2_words+20000)\n",
        "    \n",
        "    for w in label_3_words:\n",
        "      words_cond_prob_label_3[w] = (label_3_words[w]+1)/(sum_label_3_words+20000)\n",
        "\n",
        "    cond_prob[0] = words_cond_prob_label_0 \n",
        "    cond_prob[1] = words_cond_prob_label_1\n",
        "    cond_prob[2] = words_cond_prob_label_2\n",
        "    cond_prob[3] = words_cond_prob_label_3\n",
        "    \n",
        "    return cond_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU7DMgl4jFjO"
      },
      "source": [
        "def train_NB_model(X_train, y_train):\n",
        "    \"\"\"\n",
        "    training a naive bayes model from the training data.\n",
        "    Inputs:\n",
        "    - X_train: an array of shape (num_train,) which stores article titles. each entity is a string type.\n",
        "    - y_train: an array of shape (num_train,). the ground true label for each training data.\n",
        "    Output:\n",
        "    - prior: a dictionary, whose key is the class label, and value is the prior probability.\n",
        "    - conditional: a dictionary whose key is the class label y, and value is another dictionary.\n",
        "    \"\"\"\n",
        "    # compute the prior probability\n",
        "    prior = prior_prob(y_train)\n",
        "    \n",
        "    # compute the conditional probability\n",
        "    conditional = conditional_prob(X_train, y_train)\n",
        "\n",
        "    return prior, conditional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CXgF_AjkP6j"
      },
      "source": [
        "**Predicting class labels (used on test data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x6R25pnkghY"
      },
      "source": [
        "def compute_test_prob(word_count, prior_cat, cond_cat):\n",
        "    \"\"\"\n",
        "    predict the class label for one test example\n",
        "    Inputs:\n",
        "    - word_count: a dictionary which stores the frequencies of each word in the title of an article. \n",
        "                  Key is the word, value is the number of its occurrence.\n",
        "    - prior_cat: a scalar. prior probability of a specific label\n",
        "    - cond_cat: a dictionary. conditional probability of a specific label\n",
        "    Outputs:\n",
        "    - prob: posterior probability of a specific label for the test example\n",
        "    \"\"\"\n",
        "    \n",
        "    sum_cond_probs = 0\n",
        "\n",
        "    for w in word_count:\n",
        "      if w in cond_cat:\n",
        "        sum_cond_probs += word_count[w]*np.log(cond_cat[w])\n",
        "      else:\n",
        "        sum_cond_probs += word_count[w]*np.log(1/20000)\n",
        "    \n",
        "    prob = np.log(prior_cat) + sum_cond_probs\n",
        "    \n",
        "    return prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTUM9o3wqifo"
      },
      "source": [
        "def predict_label(X_test, prior_prob, cond_prob):\n",
        "    \"\"\"\n",
        "    predict the class labels for the testing set\n",
        "    Inputs:\n",
        "    - X_test: an array of shape (num_test,) which stores test data. \n",
        "              Each entity is a string type article title.\n",
        "    - prior_prob: a dictionary which stores the prior probability for all labels\n",
        "    - cond_prob: a dictionary whose key is the class label y, and value is another dictionary.\n",
        "                   In the latter dictionary, the key is word w, and the value is the\n",
        "                   conditional probability P(X_i = w | y).\n",
        "    Outputs:\n",
        "    - predict: an array that stores predicted labels\n",
        "    - test_prob: an array of shape (num_test, num_classes) which stores the posterior probability of each class\n",
        "    \"\"\"\n",
        "    \n",
        "    predict = []\n",
        "    test_prob = []\n",
        "    \n",
        "    for sms in X_test:\n",
        "      t_prob = []\n",
        "      p = []\n",
        "      s = 0\n",
        "      word_count = count_frequency([sms])\n",
        "      \n",
        "      for label in prior_prob:\n",
        "        p.append(compute_test_prob(word_count, prior_prob[label], cond_prob[label]))\n",
        "      t_prob.append(p)\n",
        "\n",
        "      max = np.max(t_prob)\n",
        "      for prob in t_prob:\n",
        "        s = np.exp(prob-max)\n",
        "        \n",
        "      for prob in t_prob:\n",
        "        test_prob.append(np.exp(prob-max)/sum(s))\n",
        "\n",
        "    predict.extend(np.argmax(test_prob, axis=1))\n",
        "\n",
        "    predict = np.array(predict)\n",
        "    test_prob = np.array(test_prob)\n",
        "      \n",
        "    return predict, test_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0W3txuA22Vd"
      },
      "source": [
        "**Predict label for test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tlQHzl-rcAG"
      },
      "source": [
        "# training naive Bayes model \n",
        "prior, cond = train_NB_model(X_train, y_train)\n",
        "\n",
        "# evaluate on test set\n",
        "y_pred, prob = predict_label(X_test, prior, cond)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvLs9G172_dv"
      },
      "source": [
        "**Compute performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQIz3rOftb-Q",
        "outputId": "4a0a40bb-f929-4e74-cb85-1fb8a36cd56d"
      },
      "source": [
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print('Testing accuracy: ', acc, '%')\n",
        "print('F1 score: ', f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy:  0.7955263157894736 %\n",
            "F1 score:  0.7951859451555987\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}